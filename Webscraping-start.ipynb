{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Webscraping-start.ipynb","provenance":[{"file_id":"1tC372u_WjqbM3PL2KhjacM1s-TGzFZQB","timestamp":1659818432985},{"file_id":"17Y70UHd_dNtY5Dyv9OIJlUXVYjW5b5qZ","timestamp":1600785325359}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"o0FydRedUP27"},"source":["# Turning a Google Colab notebook into a web app\n","\n","---\n","\n","### This notebook is designed to be used alongside Anvil's [turning a Colab notebook into a web app tutorial](https://anvil.works/learn/tutorials/google-colab-to-web-app).\n","\n","The text cells below tell you the steps you need to take to connect this notebook to an Anvil app. The steps are:\n","\n","\n","1. Install the `anvil-uplink` library\n","2. Import the `anvil.server` package\n","3. Connect the notebook using your apps Uplink key\n","4. Create a function to call from your app that includes the `anvil.server.callable` decorator\n","5. Add `anvil.server.wait_forever()` to the end of the notebook\n","\n","### Follow along below for more detail.\n","\n","---\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XRNEq2Tb5gnq"},"source":["### Let's start by installing the `anvil-uplink` library, all we need to do is add `!pip install anvil-uplink` to the first cell of the notebook:"]},{"cell_type":"code","metadata":{"id":"5BvNgFgk5dE2","executionInfo":{"status":"ok","timestamp":1660252885236,"user_tz":300,"elapsed":4558,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}},"outputId":"84565a2b-e737-4d8c-8c5f-82f63c10304e","colab":{"base_uri":"https://localhost:8080/","height":262}},"source":["!pip install anvil-uplink"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: ws4py in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.5.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n","Collecting argparse\n","  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Installing collected packages: argparse\n","Successfully installed argparse-1.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"WOjHWnhO5k0x"},"source":["### Next import the Anvil server package by adding `import anvil.server`:\n","\n","Importing `anvil.server` means, when this notebook is connected via the Uplink, it will behave in the same way as any other [Anvil Server Module](https://anvil.works/docs/server)."]},{"cell_type":"code","metadata":{"id":"EML6wBYQ5fiM","executionInfo":{"status":"ok","timestamp":1660252885237,"user_tz":300,"elapsed":14,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}}},"source":["import anvil.server"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RV2ze8a7ScHo"},"source":["### Then connect this notebook to your app using your Uplink key `anvil.server.connect(\"your-uplink-key\")`:\n","\n","For information on how to get your apps Uplink key, see [Step 4 - Enable the Uplink](https://anvil.works/learn/tutorials/google-colab-to-web-app#step-4-enable-the-uplink)."]},{"cell_type":"code","metadata":{"id":"MA9-qSCOSckw","executionInfo":{"status":"ok","timestamp":1660252885237,"user_tz":300,"elapsed":13,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}}},"source":["anvil.server.connect(\"DAPAOJPOQFFRAFTAOLZBRB7K-YSRPAJWPBRTZT4FC\")"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mlf9a7vM_PVF"},"source":["### Build and train the classification model\n","\n","The next cell gets the dataset, finds an optimal number of neighbours and then builds and trains the model. How this works is outside the scope of this tutorial, however, if you want to read more about how the code below works, Towards Data Science has a useful article [here](https://towardsdatascience.com/knn-using-scikit-learn-c6bed765be75).\n","\n","#### *We don't need to change anything in the next cell.*\n"]},{"cell_type":"code","source":["pip install requests beautifulsoup4 lxml "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwshozvyAgg2","executionInfo":{"status":"ok","timestamp":1660252888793,"user_tz":300,"elapsed":3568,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}},"outputId":"a04eaf88-1c06-4329-9258-40a954b2615a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.9.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup as soup\n","import pandas as pd\n","from typing import Text\n","from pandas.io.formats.format import TextAdjustment"],"metadata":{"id":"KYRFTL8WAmsO","executionInfo":{"status":"ok","timestamp":1660252889276,"user_tz":300,"elapsed":489,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!pip install selenium"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":907},"id":"G3cDd3rdAqh2","executionInfo":{"status":"ok","timestamp":1660252907016,"user_tz":300,"elapsed":17745,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}},"outputId":"0af4dd77-d39f-4604-a43b-d495bd75b7bb"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting selenium\n","  Downloading selenium-4.4.0-py3-none-any.whl (985 kB)\n","\u001b[K     |████████████████████████████████| 985 kB 3.8 MB/s \n","\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n","  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 43.0 MB/s \n","\u001b[?25hCollecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n","Collecting trio~=0.17\n","  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n","\u001b[K     |████████████████████████████████| 358 kB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Collecting sniffio\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Collecting outcome\n","  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n","Collecting async-generator>=1.9\n","  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n","Collecting pyOpenSSL>=0.14\n","  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 2.1 MB/s \n","\u001b[?25hCollecting cryptography>=1.3.4\n","  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 37.0 MB/s \n","\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n","Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.11 which is incompatible.\u001b[0m\n","Successfully installed async-generator-1.10 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.4.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 urllib3-1.26.11 wsproto-1.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}]},{"cell_type":"code","source":["\"\"\"convocatoria = 'ayuda economica'\n","clave = 'mujeres'\"\"\""],"metadata":{"id":"daBCHJ9EOdNV","executionInfo":{"status":"ok","timestamp":1660252907018,"user_tz":300,"elapsed":26,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"95a0b7d6-6b5f-4cba-8490-ccfad8ed8007"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"convocatoria = 'ayuda economica'\\nclave = 'mujeres'\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#Obtener datos búqueda en google\n","\n","headers = {\n","\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\",\n","\"Accept-Encoding\":\"gzip, deflate\",\n","\"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n","\"DNT\":\"1\"\n","}\n","\n","df = pd.DataFrame(columns = ['palabra clave', 'titulo', 'enlace', 'descripcion'])\n","\n","def obtener_resultados(termino_busqueda, numero_resultados, codigo_lenguaje):\n","  url_google = 'https://www.google.com/search?q={}&num={}&h1={}'.format(termino_busqueda, numero_resultados, codigo_lenguaje)\n","  respuesta = requests.get(url_google, headers = headers)\n","  respuesta.raise_for_status()\n","  return termino_busqueda, respuesta.text\n","\n","def procesar_resultados(html, palabra):\n","  soup_response = soup(html, 'html.parser')\n","  bloque = soup_response.find_all(\"div\", class_=\"g\")\n","  global df  \n","  df = df.drop(df.index[range(0, df.shape[0])])\n","  \n","  for resultado in bloque:\n","    titulo = resultado.find('h3').get_text()\n","    enlaces = resultado.find('a',href=True).get('href')\n","    if resultado.find('div', {\"class\": \"VwiC3b yXK7lf MUxGbd yDYNvb lyLwlc lEBKkf\"}) is not None:\n","        descripciones = resultado.find('div', {\"class\": \"VwiC3b yXK7lf MUxGbd yDYNvb lyLwlc lEBKkf\"}).get_text()\n","    else:\n","      descripciones = 'Visita página web'\n","\n","    df = df.append({'palabra clave' : palabra, \n","                    'titulo' : titulo, \n","                    'enlace' : enlaces, \n","                    'descripcion' : descripciones},\n","                    ignore_index = True)   \n","  return df\n","\n","def scrap(termino_busqueda, numero_resultados, codigo_lenguaje):\n","  palabra, html = obtener_resultados(termino_busqueda, numero_resultados, codigo_lenguaje)\n","  resultados = procesar_resultados(html, palabra)\n","  return resultados"],"metadata":{"id":"zeDjukGZCWiW","executionInfo":{"status":"ok","timestamp":1660252907020,"user_tz":300,"elapsed":23,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Creación de variables a partir de datos de búsqueda\n","\n","#para extraer palabras clave\n","d = {'migrantes' : ['migrantes', 'migrante', 'migraciones'],\n","     'vejez' : ['vejez', 'personas mayores', 'ancianos'],\n","     'niñez': [\"niñez\", 'niños', 'niñas', 'infancia', 'menores', 'infantil', 'nino', 'nina', 'ninos', 'ninas'],\n","     'adolescentes': ['adolescentes', 'jovenes', 'jóvenes', 'adolescencia'],\n","     'mujeres' : ['mujeres', 'mujer', 'igualdad de género'],\n","     'salud': ['salud', 'enfermedades', 'enfermedad', 'médica', 'medica'],\n","     'educacion': ['educacion', 'educación', 'aprendizaje', 'becas', 'beca', 'estudiantes', 'estudiante', 'alfabetización', 'alfabetizacion', 'escolar', 'escuela', 'colegio', 'educar', 'educativo', 'alumano', 'alumnos'],\n","     'alimentacion': ['alimentacion', 'alimentación', 'alimentos', 'hambre', 'alimentario', 'comida', 'alimentaria', 'nutrición', 'nutricion'],\n","     'ambiental' : ['ambiental', 'medio ambiente'],\n","     'seguridad' : ['seguridad'],\n","     'comunitario' : ['comunicatorio', 'comunitaria'],\n","     'ciencia' : ['ciencia'],\n","     'tecnologia' : ['tecnologia', 'tecnología', 'innovacion', 'innovación'],\n","     'naciones unidas' : ['naciones unidas', 'onu'],\n","     'sexualidad' : ['sexualidad'],\n","     'salubridad' : ['salubridad', 'saneamiento'],\n","     'desastres' : ['desastres', 'desastre natural', 'desastre'],\n","     'discapacidad' : ['discapacidad', 'discapacitados', 'discapacitada', 'discapacitado'],\n","     'vulnerabilidad' : ['vulnerabilidad', 'vulnerables', 'vulnerable'],\n","     'pobreza' : ['pobreza', 'pobre', 'pobres', 'pago'],\n","     }\n","\n","def mapper(val):\n","    for key, values in d.items():\n","        if any(value in val for value in values):\n","            return key\n","    return 'Otros'\n","\n","def palabra_clave(resultados):\n","  resultados['clave'] = resultados['titulo'].map(mapper)\n","\n","  if 'Otros' in resultados['clave']:\n","    resultados['clave'] = resultados['descripcion'].map(mapper)\n","\n","  return resultados\n","\n","# Para extraer pais\n","Pais = {'COLOMBIA' : ['colombia', '.co.', '.co/'],\n","        'ESPAÑA' : ['españa', '.es.', '.es/'],\n","        'ARGENTINA' : ['argentina', '.ar.', '.ar/'],\n","        'BOLIVIA' : ['bolivia', '.bo.', '.bo/'],\n","        'BRASIL' : ['brasil', 'brazil', '.br.', '.br/'],\n","        'CHILE' : ['chile', '.cl.', '.cl/'],\n","        'COSTA RICA' : ['costa rica', '.cr.', '.cr/'],\n","        'CUBA': ['cuba', '.cu.', '.cu/'],\n","        'ECUADOR' : ['ecuador', '.ec.', '.ec/'],\n","        'EL SALVADOR' : ['el salvador', '.sv.', '.sv/'],\n","        'ESTADOS UNIDOS' : ['estados unidos', '.us.', '.us/', '.usa.'],\n","        'GUATEMALA' : ['guatemala', '.gt.', '.gt/'],\n","        'GUYANA' : ['guyana', '.gf.', '.gf/'],\n","        'HAITI': ['haiti', 'haití', '.ht.', '.ht/'],\n","        'HONDURAS' : ['honduras', '.hn.', '.hn/'],\n","        'MEXICO' : ['mexico', 'méxico', '.mx.', '.mx/'],\n","        'NICARAGUA' : ['nicaragua', '.ni.', '.ni/'],\n","        'PANAMA' : ['panamá', 'panama', '.pa.', '.pa/'],\n","        'PARAGUAY' : ['paraguay', '.py.', '.py/'],\n","        'PERU' : ['perú', 'peru', '.pe.', '.pe/'],\n","        'REPUBLICA DOMINICANA' : ['república dominicana', 'republica dominicana', '.do,', '.do/'],\n","        'URUGUAY' : ['uruguay', '.uy.', '.uy/'],\n","        'VENEZUELA' : ['venezuela', '.ve.', '.ve/']\n","        }\n","    \n","def mapper1(val):\n","    for key, values in Pais.items():\n","        if any(value in val for value in values):\n","            return key\n","    return 'Por identificar'\n","\n","def variable_pais(resultados):\n","  resultados['Pais'] = resultados.enlace.map(mapper1)\n","\n","  return resultados\n","\n","#Para extraer ODS\n","ODS = {'1' : ['pobreza', 'migrantes', 'vulnerabilidad', 'vulnerables', 'vulnerable', 'desastres', 'desastre natural', 'desastre', 'pobre', 'pobres',\n","              'pago', 'migrante', 'emigrante',  'migraciones', 'ayuda financiera'],\n","       '2' : ['alimentacion', 'alimentación', 'alimentos', 'hambre', 'alimentario', 'comida', 'alimentaria', 'nutrición', 'nutricion'],\n","       '3' : ['salud', 'enfermedades', 'enfermedad', 'médica', 'medica', 'sexualidad'],\n","       '4' : ['educacion', 'educación', 'aprendizaje', 'becas', 'beca', 'estudiantes', 'estudiante', 'alfabetización', 'alfabetizacion', \n","              'escolar', 'escuela', 'colegio', 'educar', 'educativo', 'alumno', 'alumnos'],\n","       '5' : ['mujeres','mujer', 'igualdad de género'],\n","       '6' : ['salubridad', 'saneamiento'],\n","       '7' : ['energia'],\n","       '8' : ['trabajo'],\n","       '9' : ['ciencia', 'tecnologia', 'tecnología', 'innovacion', 'innovación', 'programación', 'tic'],\n","       '10' : ['discapacidad', 'discapacitados', 'discapacitada', 'discapacitado'],\n","       '11' : ['comunitario', 'sostenibilidad', 'seguridad', 'comunitaria'],\n","       '12' : ['produccion', 'consumo', 'producción'],\n","       '13' : ['ambiental', 'medio ambiente', 'clima'],\n","       '14' : ['mar', 'oceano', 'mares', 'peces'],\n","       '15' : ['ecosistema', 'ecosistemas'],\n","       '16' : ['paz', 'justicia', 'corrupción'],\n","       '17' : ['alianza', 'alianzas']\n","       }\n","    \n","def mapper2(val):\n","    for key, values in ODS.items():\n","        if any(value in val for value in values):\n","            return key\n","    return 'Por identificar'\n","\n","def variable_ODS(resultados):\n","  resultados['ODS'] = resultados['titulo'].map(mapper2)\n","\n","  if 'Por identificar' in resultados['ODS']:\n","    resultados['ODS'] = resultados['descripcion'].map(mapper2)\n","  \n","  return resultados\n","\n","\n","#Para extraer beneficiarios\n","Beneficiarios = {'niños y niñas' : ['niñez'],\n","                 'adulto mayor' : ['vejez'],\n","                 'jovenes' : ['adolescentes'],\n","                 'mujeres' : ['mujeres'],\n","                 'migrantes' : ['migrantes']\n","                 }\n","\n","def mapper3(val):\n","    for key, values in Beneficiarios.items():\n","        if any(value in val for value in values):\n","            return key\n","    return 'mixto'\n","\n","def variable_beneficiarios(resultados):\n","  resultados['Beneficiarios'] = resultados.clave.map(mapper3)\n","\n","  if 'mixto' in resultados['Beneficiarios']:\n","    resultados['Beneficiarios'] = resultados['Beneficiarios'].map(mapper3)\n","  \n","  return resultados"],"metadata":{"id":"-5L-M8M0UNvJ","executionInfo":{"status":"ok","timestamp":1660252907452,"user_tz":300,"elapsed":453,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gdil_W7b-N9Z"},"source":["### Next, we will create our `predict_iris()` function with a `@anvil.server.callable` decorator. The decorator makes the function callable from our Anvil app. \n","Add the following code to the next cell:\n","```\n","@anvil.server.callable\n","def predict_iris(sepal_length, sepal_width, petal_length, petal_width):\n","  classification = knn.predict([[sepal_length, sepal_width, petal_length, petal_width]])\n","  return iris.target_names[classification][0]\n","```\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ChnTYxx3-MRt","executionInfo":{"status":"ok","timestamp":1660252907453,"user_tz":300,"elapsed":9,"user":{"displayName":"Alexandra La Cruz","userId":"00088263801389656665"}}},"source":["@anvil.server.callable\n","def bdresultados(convocatoria, clave):\n","  convocatoria = convocatoria.split(',')\n","  clave = clave.split(',')\n","  palabra = []\n","\n","  for i in convocatoria:\n","    for j in clave:\n","      concat = str(i+\" + \"+j)\n","      palabra.append(concat)\n","\n","  resultados = pd.DataFrame(columns = ['palabra clave', 'titulo', 'enlace', 'descripcion'])  \n","\n","  for i in palabra:\n","    resultados = pd.concat([resultados, scrap(i, 5, \"es\")])\n","\n","  resultados = resultados.drop_duplicates(keep='last', subset=\"titulo\")\n","  resultados = resultados.reset_index()\n","  resultados = resultados.drop(columns=['index'])\n","  resultados['titulo'] =  resultados['titulo'].str.lower()\n","  resultados['descripcion'] =  resultados['descripcion'].str.lower()\n","\n","  resultados = palabra_clave(resultados)\n","  resultados = variable_pais(resultados)\n","  resultados = variable_ODS(resultados)\n","  resultados = variable_beneficiarios(resultados)\n","\n","  bd = resultados.to_csv()\n","    \n","  return bd"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y54Z7Ano6wT4"},"source":["### Finally, let's add `anvil.server.wait_forever()` function so the notebook is always available to the web app:"]},{"cell_type":"code","metadata":{"id":"JF1L5rHt6wh6"},"source":["anvil.server.wait_forever()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WR1p147uXX0z"},"source":["---\n","\n","## That's it, 5 simple steps to connect your notebook to your Anvil app! \n","\n","---"]}]}